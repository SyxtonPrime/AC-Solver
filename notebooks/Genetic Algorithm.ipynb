{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to set up a Genetic algorithm which to learn an improvement on the naive greedy search approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from importlib import resources\n",
    "from ac_solver.envs.utils import is_presentation_trivial\n",
    "from ac_solver.envs.ac_moves import ACMove\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a helper functions. Whilst we could plug our presentations directly into a neural network, it will likely help the network out if we first convert to a one-hot encoding.\n",
    "\n",
    "Given that out generators come in $(x, x^{-1})$ pairs, it makes sense for the one hot encodings of $x$ and $x^{-1}$ to be the negatives of each other. Hence we map $x^{\\pm 1} \\to [\\pm 1, 0]$ and $y^{\\pm 1} \\to [0, \\pm 1]$.\n",
    "\n",
    "Depending on how things go, it might also be worth investigating a one-hot encoding which outputs an array of length $4$. Perhaps it simply isn't worth including our logic about generators being inverses. \n",
    "\n",
    "Fixing length of each relation to be $N$, we end up with a matrix of size $2\\times N\\times 2$. Observe that, our problem exhibits equivariance with respect to the group of order 16: $\\mathbb{Z}/2 \\times D_4$. This groups is generated by three transformations: \n",
    "- Swapping the relations $r_1 \\leftrightarrow r_2$.\n",
    "- Swapping the generators $x \\leftrightarrow y$.\n",
    "- Swapping a generators with it's inverse $x \\leftrightarrow x^{-1}$.\n",
    "\n",
    "Each of these transformations has order $2$ but while the first transformation commutes with everything else, transformations two and three do not commute.\n",
    "\n",
    "It would be interesting to investigate if we could make the network equivariant with respect to this group but for now we just flatten the tensor to make a vector of length $4N$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert\n",
    "def one_hot_single(elem: int) -> np.typing.NDArray[np.int32]:\n",
    "    if elem == -2:\n",
    "        return [0, -1]\n",
    "    elif elem == -1:\n",
    "        return [-1, 0]\n",
    "    elif elem == 0:\n",
    "        return [0, 0]\n",
    "    elif elem == 1:\n",
    "        return [1, 0]\n",
    "    elif elem == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        raise Exception(\"Unexpected Token Found\")\n",
    "\n",
    "# Convert from the standard presentation to a one_hot encoding mapping a generator to 1 and its inverse to -1.\n",
    "# We pad the output to length outlen.\n",
    "def to_one_hot(presentation: np.typing.NDArray[np.int32], out_len: int) -> np.typing.NDArray[np.int32]:\n",
    "    relator_len = len(presentation) // 2\n",
    "    first_relator = [one_hot_single(presentation[x]) for x in range(0, relator_len)] + [[0, 0]] * (out_len - relator_len)\n",
    "    second_relator = [one_hot_single(presentation[x + relator_len]) for x in range(0, relator_len)] + [[0, 0]] * (out_len - relator_len)\n",
    "\n",
    "    relator_pair = np.array(first_relator + second_relator, dtype=np.float32)\n",
    "    return relator_pair.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to set up the training environment. Essentially we will be doing a greedy like search where we replace our standard metric (i.e. the length of the relators) with a new learned metric.\n",
    "\n",
    "To help out, we will have a temperature parameter which will initially include the length of the relators but will be slowly phased out over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(net, presentation, pres_len, out_len, temperature):\n",
    "    one_hot_pres = torch.from_numpy(to_one_hot(presentation, out_len))\n",
    "    eval = net(one_hot_pres).item()\n",
    "    return eval - pres_len * temperature\n",
    "    \n",
    "\n",
    "def search(\n",
    "        presentation: np.typing.NDArray[np.int32],\n",
    "        net,\n",
    "        temperature,\n",
    "        out_len,\n",
    "        max_nodes_to_explore: int = 100) -> bool:\n",
    "    max_relator_length = len(presentation) // 2\n",
    "    first_word_length = np.count_nonzero(presentation[:max_relator_length])\n",
    "    second_word_length = np.count_nonzero(presentation[max_relator_length:])\n",
    "\n",
    "    word_lengths = [first_word_length, second_word_length]\n",
    "\n",
    "    max_score = score(net, presentation, word_lengths[0] + word_lengths[1], out_len, temperature)\n",
    "    current_state = presentation\n",
    "    for i in range(max_nodes_to_explore):\n",
    "        # print(current_state, max_score)\n",
    "        current_beaten = False\n",
    "        for action in range(0, 12):\n",
    "            new_state, new_word_lengths = ACMove(\n",
    "                action,\n",
    "                current_state,\n",
    "                max_relator_length,\n",
    "                word_lengths,\n",
    "                cyclical=True,\n",
    "            )\n",
    "            new_state_score = score(net, new_state, new_word_lengths[0] + new_word_lengths[1], out_len, temperature)\n",
    "            # print(new_state, new_state_score)\n",
    "            if new_state_score > max_score:\n",
    "                current_beaten = True\n",
    "                max_score = new_state_score\n",
    "                best_state = new_state\n",
    "                best_lengths = new_word_lengths\n",
    "        \n",
    "        if current_beaten:\n",
    "            if best_lengths[0] + best_lengths[1] == 2:\n",
    "                return i\n",
    "            current_state = best_state\n",
    "            word_lengths = best_lengths\n",
    "        else:\n",
    "            return 0\n",
    " \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = torch.nn.Linear(80, 90)\n",
    "        self.hid2 = torch.nn.Linear(90, 90)\n",
    "        self.outp = torch.nn.Linear(90, 1)\n",
    "\n",
    "        torch.nn.init.uniform_(self.hid1.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid1.bias, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid2.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid2.bias, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.outp.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.outp.bias, -0.5, 0.5)\n",
    "\n",
    "        self.hid1.requires_grad_(False)\n",
    "        self.hid2.requires_grad_(False)\n",
    "        self.outp.requires_grad_(False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = torch.relu(self.hid1(x))\n",
    "        z = torch.relu(self.hid2(z))\n",
    "        return torch.relu(self.outp(z))\n",
    "    \n",
    "    def mutate(self, num_copies, scale):\n",
    "        output_nets = [copy.deepcopy(self)]\n",
    "        for _ in range(num_copies - 1):\n",
    "            clone = copy.deepcopy(self)\n",
    "            for param in clone.parameters():\n",
    "                rand = torch.randn(param.size())\n",
    "                param += 0.03 * scale * rand\n",
    "            output_nets += [clone]\n",
    "        return output_nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "with open(\"../ac_solver/search/miller_schupp/data/all_presentations.txt\") as file:\n",
    "    presentations = [np.array(literal_eval(path)) for path in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrubbed_presentations = []\n",
    "swapped_presentations = []\n",
    "for presentation in presentations:\n",
    "    if len(presentation) == 40:\n",
    "        new_pres = presentation\n",
    "    elif len(presentation) > 40:\n",
    "        new_pres = np.zeros(40)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:20:] = presentation[:20:]\n",
    "        new_pres[20::] = presentation[len_rels:len_rels + 20:]\n",
    "    elif len(presentation) < 40:\n",
    "        new_pres = np.zeros(40)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:len_rels:] = presentation[:len_rels:]\n",
    "        new_pres[20:20 + len_rels:] = presentation[len_rels::]\n",
    "    scrubbed_presentations += [new_pres]\n",
    "    swap_pres = np.zeros(40)\n",
    "    swap_pres[:20] = new_pres[20:]\n",
    "    swap_pres[20:] = new_pres[:20]\n",
    "    swapped_presentations += [swap_pres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nets = [Net() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:02<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:05<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:05<01:07,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\AngusGruen\\AppData\\Local\\Temp\\ipykernel_43388\\668976750.py\", line 7, in <module>\n",
      "    if search(presentation, net, 1, 20):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AngusGruen\\AppData\\Local\\Temp\\ipykernel_43388\\3512859880.py\", line 32, in search\n",
      "    new_state_score = score(net, new_state, new_word_lengths[0] + new_word_lengths[1], out_len, temperature)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\AngusGruen\\AppData\\Local\\Temp\\ipykernel_43388\\3512859880.py\", line 3, in score\n",
      "    eval = net(one_hot_pres).item()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "  File \"C:\\Users\\AngusGruen\\AppData\\Local\\Temp\\ipykernel_43388\\4179581017.py\", line 22, in forward\n",
      "    return torch.relu(self.outp(z))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "nets = [Net() for _ in range(100)]\n",
    "for i in range(100):\n",
    "    temp = 1 / (1 + (i // 5))\n",
    "    accs = np.array([0 for _ in range(100)])\n",
    "    for presentation in tqdm.tqdm(scrubbed_presentations[:100:]):\n",
    "        for (j, net) in enumerate(nets):\n",
    "            if search(presentation, net, 1, 20):\n",
    "                accs[j] += 1\n",
    "    print(i, max(accs))\n",
    "\n",
    "    best_nets = [nets[k] for k in np.argpartition(accs, -10)[-10:]]\n",
    "    mutated_nets = [net.mutate(10, temp) for net in best_nets]\n",
    "    nets = [net \n",
    "            for mutated_net in mutated_nets\n",
    "            for net in mutated_net \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1190it [00:13, 90.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 13\n",
      "49 7\n",
      "57 7\n",
      "56 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc, acc_neg, acc_swap, acc_swap_neg = 0, 0, 0, 0\n",
    "max_len, max_len_neg, max_len_swap, max_len_swap_neg = 0, 0, 0, 0\n",
    "for (j, presentation) in tqdm.tqdm(enumerate(scrubbed_presentations)):\n",
    "    i = search(presentation, nets[0], 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "\n",
    "    i_neg = search(-presentation, nets[0], 1, 20)\n",
    "    if i_neg:\n",
    "        max_len_neg = max(max_len_neg, i_neg)\n",
    "        acc_neg += 1\n",
    "    \n",
    "    i_swap = search(swapped_presentations[j], nets[0], 1, 20)\n",
    "    if i_swap:\n",
    "        max_len_swap = max(max_len_swap, i_swap)\n",
    "        acc_swap += 1\n",
    "    \n",
    "    i_swap_neg = search(-swapped_presentations[j], nets[0], 1, 20)\n",
    "    if i_swap_neg:\n",
    "        max_len_swap_neg = max(max_len_swap_neg, i_swap_neg)\n",
    "        acc_swap_neg += 1\n",
    "print(acc, max_len)\n",
    "print(acc_neg, max_len_neg)\n",
    "print(acc_swap, max_len_swap)\n",
    "print(acc_swap_neg, max_len_swap_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1190it [00:05, 216.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 7\n",
      "56 7\n",
      "53 7\n",
      "53 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_net(pres):\n",
    "    return torch.zeros(1)\n",
    "\n",
    "acc, acc_neg, acc_swap, acc_swap_neg = 0, 0, 0, 0\n",
    "max_len, max_len_neg, max_len_swap, max_len_swap_neg = 0, 0, 0, 0\n",
    "for (j, presentation) in tqdm.tqdm(enumerate(scrubbed_presentations)):\n",
    "    i = search(presentation, zero_net, 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "\n",
    "    i_neg = search(-presentation, zero_net, 1, 20)\n",
    "    if i_neg:\n",
    "        max_len_neg = max(max_len_neg, i_neg)\n",
    "        acc_neg += 1\n",
    "    \n",
    "    i_swap = search(swapped_presentations[j], zero_net, 1, 20)\n",
    "    if i_swap:\n",
    "        max_len_swap = max(max_len_swap, i_swap)\n",
    "        acc_swap += 1\n",
    "    \n",
    "    i_swap_neg = search(-swapped_presentations[j], zero_net, 1, 20)\n",
    "    if i_swap_neg:\n",
    "        max_len_swap_neg = max(max_len_swap_neg, i_swap_neg)\n",
    "        acc_swap_neg += 1\n",
    "print(acc, max_len)\n",
    "print(acc_neg, max_len_neg)\n",
    "print(acc_swap, max_len_swap)\n",
    "print(acc_swap_neg, max_len_swap_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -2., -1.,  2.,  2., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "       -0., -0., -0., -0., -0., -0., -0.,  1., -2., -0., -0., -0., -0.,\n",
       "       -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "       -0.])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scrubbed_presentations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
