{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to set up a Genetic algorithm which to learn an improvement on the naive greedy search approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from importlib import resources\n",
    "from ac_solver.envs.utils import is_presentation_trivial\n",
    "from ac_solver.envs.ac_moves import ACMove\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a helper functions. Whilst we could plug our presentations directly into a neural network, it will likely help the network out if we first convert to a one-hot encoding.\n",
    "\n",
    "Given that out generators come in $(x, x^{-1})$ pairs, it makes sense for the one hot encodings of $x$ and $x^{-1}$ to be the negatives of each other. Hence we map $x^{\\pm 1} \\to [\\pm 1, 0]$ and $y^{\\pm 1} \\to [0, \\pm 1]$.\n",
    "\n",
    "Depending on how things go, it might also be worth investigating a one-hot encoding which outputs an array of length $4$. Perhaps it simply isn't worth including our logic about generators being inverses. \n",
    "\n",
    "Fixing length of each relation to be $N$, we end up with a matrix of size $2\\times N\\times 2$. Observe that, our problem exhibits equivariance with respect to the group of order 16: $\\mathbb{Z}/2 \\times D_4$. This groups is generated by three transformations: \n",
    "- Swapping the relations $r_1 \\leftrightarrow r_2$.\n",
    "- Swapping the generators $x \\leftrightarrow y$.\n",
    "- Swapping a generators with it's inverse $x \\leftrightarrow x^{-1}$.\n",
    "\n",
    "Each of these transformations has order $2$ but while the first transformation commutes with everything else, transformations two and three do not commute.\n",
    "\n",
    "It would be interesting to investigate if we could make the network equivariant with respect to this group but for now we just flatten the tensor to make a vector of length $4N$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the two relations of a given presentation.\n",
    "def swap_relations(presentation, relation_length):\n",
    "    new_presentation = np.zeros(2 * relation_length)\n",
    "    new_presentation[:relation_length] = presentation[relation_length:]\n",
    "    new_presentation[relation_length:] = presentation[:relation_length]\n",
    "    return new_presentation\n",
    "\n",
    "# Swap the two generators of a given presentation.\n",
    "def swap_generators(presentation, relation_length):\n",
    "    new_presentation = np.zeros(2 * relation_length)\n",
    "    for (i, elem) in enumerate(presentation):\n",
    "        if elem > 0:\n",
    "            # Map 2 -> 1 and 1 -> 2\n",
    "            new_presentation[i] = 3 - elem\n",
    "        elif elem < 0:\n",
    "            # Map -2 -> -1 and -1 -> -2\n",
    "            new_presentation[i] = -3 - elem\n",
    "    return new_presentation\n",
    "\n",
    "# Swap the first generator with its inverse\n",
    "def invert_x(presentation, relation_length):\n",
    "    new_presentation = copy.copy(presentation)\n",
    "    for (i, elem) in enumerate(presentation):\n",
    "        if elem == 1:\n",
    "            # Map 1 -> -1\n",
    "            new_presentation[i] = -1\n",
    "        elif elem == -1:\n",
    "            # Map -1 -> 1\n",
    "            new_presentation[i] = 1\n",
    "\n",
    "    return new_presentation\n",
    "\n",
    "# Find all sixteen equivalent presentations related to the original by our equivariance group.\n",
    "# \n",
    "# Each element of the equivariance group can be written uniquely as (g1)^{i1}*(g2)^{i2}*(g3)^{i3}*(g4)^{i4}\n",
    "# where i1, i2, i3, i4 as 0 or 1 and\n",
    "# g4: Swap the relations.\n",
    "# g3: Swap the generators.\n",
    "# g2: Swap the first generator with its inverse.\n",
    "# g1: Swap both generators with their inverse.\n",
    "# Note that  g1(P) = g3 * g2 * g3 * g2(P) so it isn't a \"true\" generator but its good enough for here.\n",
    "def group_equivalency_class(presentation, relation_length):\n",
    "    equivalence_class = [presentation]\n",
    "    equivalence_class += [swap_relations(presentation, relation_length)]\n",
    "    equivalence_class += [swap_generators(pres, relation_length) for pres in equivalence_class]\n",
    "    equivalence_class += [invert_x(pres, relation_length) for pres in equivalence_class]\n",
    "    equivalence_class += [-pres for pres in equivalence_class]\n",
    "\n",
    "    return equivalence_class\n",
    "\n",
    "\n",
    "\n",
    "# Convert an element from the {+/- 2, +/- 1, 0} representation into the one-hot representation.  \n",
    "def one_hot_single(elem: int) -> np.typing.NDArray[np.int32]:\n",
    "    if elem == -2:\n",
    "        return [0, -1]\n",
    "    elif elem == -1:\n",
    "        return [-1, 0]\n",
    "    elif elem == 0:\n",
    "        return [0, 0]\n",
    "    elif elem == 1:\n",
    "        return [1, 0]\n",
    "    elif elem == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        raise Exception(\"Unexpected Token Found\")\n",
    "\n",
    "# Convert from the standard presentation to a one_hot encoding mapping a generator to 1 and its inverse to -1.\n",
    "# We pad the output to length outlen.\n",
    "def to_one_hot(presentation: np.typing.NDArray[np.int32], out_len: int) -> np.typing.NDArray[np.int32]:\n",
    "    relator_len = len(presentation) // 2\n",
    "    first_relator = [one_hot_single(presentation[x]) for x in range(0, relator_len)] + [[0, 0]] * (out_len - relator_len)\n",
    "    second_relator = [one_hot_single(presentation[x + relator_len]) for x in range(0, relator_len)] + [[0, 0]] * (out_len - relator_len)\n",
    "\n",
    "    relator_pair = np.array(first_relator + second_relator, dtype=np.float32)\n",
    "    return relator_pair.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to set up the training environment. Essentially we will be doing a greedy like search where we replace our standard metric (i.e. the length of the relators) with a new learned metric.\n",
    "\n",
    "To help out, we will have a temperature parameter which will initially include the length of the relators but will be slowly phased out over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(net, presentation, pres_len, out_len, temperature):\n",
    "    one_hot_pres = torch.from_numpy(to_one_hot(presentation, out_len))\n",
    "    eval = net(one_hot_pres).item()\n",
    "    return eval + pres_len * temperature\n",
    "    \n",
    "\n",
    "def search(\n",
    "        presentation: np.typing.NDArray[np.int32],\n",
    "        net,\n",
    "        temperature,\n",
    "        out_len,\n",
    "        max_nodes_to_explore: int = 100) -> bool:\n",
    "    max_relator_length = len(presentation) // 2\n",
    "    first_word_length = np.count_nonzero(presentation[:max_relator_length])\n",
    "    second_word_length = np.count_nonzero(presentation[max_relator_length:])\n",
    "\n",
    "    word_lengths = [first_word_length, second_word_length]\n",
    "\n",
    "    min_score = score(net, presentation, word_lengths[0] + word_lengths[1], out_len, temperature)\n",
    "    current_state = presentation\n",
    "    for i in range(max_nodes_to_explore):\n",
    "        # print(current_state, max_score)\n",
    "        current_beaten = False\n",
    "        for action in range(12):\n",
    "            new_state, new_word_lengths, state_updated = ACMove(\n",
    "                action,\n",
    "                current_state,\n",
    "                max_relator_length,\n",
    "                word_lengths,\n",
    "                cyclical=False,\n",
    "            )\n",
    "            if state_updated:\n",
    "                new_state_score = score(net, new_state, new_word_lengths[0] + new_word_lengths[1], out_len, temperature)\n",
    "                # print(new_state, new_state_score)\n",
    "                if new_state_score <= min_score:\n",
    "                    current_beaten = True\n",
    "                    min_score = new_state_score\n",
    "                    best_state = new_state\n",
    "                    best_lengths = new_word_lengths\n",
    "        \n",
    "        if current_beaten:\n",
    "            if best_lengths[0] + best_lengths[1] == 2:\n",
    "                return i\n",
    "            current_state = best_state\n",
    "            word_lengths = best_lengths\n",
    "        else:\n",
    "            return 0\n",
    " \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = torch.nn.Linear(80, 90)\n",
    "        self.hid2 = torch.nn.Linear(90, 90)\n",
    "        self.hid3 = torch.nn.Linear(90, 90)\n",
    "        self.outp = torch.nn.Linear(90, 1)\n",
    "\n",
    "        torch.nn.init.uniform_(self.hid1.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid1.bias, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid2.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid2.bias, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid3.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.hid3.bias, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.outp.weight, -0.5, 0.5)\n",
    "        torch.nn.init.uniform_(self.outp.bias, -0.5, 0.5)\n",
    "\n",
    "        self.hid1.requires_grad_(False)\n",
    "        self.hid2.requires_grad_(False)\n",
    "        self.hid3.requires_grad_(False)\n",
    "        self.outp.requires_grad_(False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = torch.relu(self.hid1(x))\n",
    "        z = torch.relu(self.hid2(z))\n",
    "        z = torch.relu(self.hid3(z))\n",
    "        return torch.relu(self.outp(z))\n",
    "    \n",
    "    def mutate(self, num_copies, scale):\n",
    "        output_nets = [copy.deepcopy(self)]\n",
    "        for _ in range(num_copies - 1):\n",
    "            clone = copy.deepcopy(self)\n",
    "            for param in clone.parameters():\n",
    "                rand = torch.randn(param.size())\n",
    "                param += 0.03 * scale * rand\n",
    "            output_nets += [clone]\n",
    "        return output_nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "with open(\"../ac_solver/search/miller_schupp/data/all_presentations.txt\") as file:\n",
    "    miller_presentations = [np.array(literal_eval(path)) for path in file.readlines()]\n",
    "\n",
    "## Load data\n",
    "with open(\"../ac_solver/search/miller_schupp/data/simple_presentations.txt\") as file:\n",
    "    simple_presentations = [np.array(literal_eval(path)) for path in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190\n",
      "19040\n"
     ]
    }
   ],
   "source": [
    "desired_length = 20\n",
    "scrubbed_miller_presentations = []\n",
    "equivariant_miller_presentation_set = []\n",
    "for presentation in miller_presentations:\n",
    "    if len(presentation) == 2*desired_length:\n",
    "        new_pres = presentation\n",
    "    elif len(presentation) > 2*desired_length:\n",
    "        new_pres = np.zeros(2 * desired_length)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:desired_length:] = presentation[:desired_length:]\n",
    "        new_pres[desired_length::] = presentation[len_rels:len_rels + desired_length:]\n",
    "    elif len(presentation) < 2*desired_length:\n",
    "        new_pres = np.zeros(2 * desired_length)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:len_rels:] = presentation[:len_rels:]\n",
    "        new_pres[desired_length:desired_length + len_rels:] = presentation[len_rels::]\n",
    "    scrubbed_miller_presentations += [new_pres]\n",
    "    equivariant_miller_presentation_set += group_equivalency_class(new_pres, 20)\n",
    "\n",
    "print(len(scrubbed_miller_presentations))\n",
    "print(len(equivariant_miller_presentation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "desired_length = 20\n",
    "scrubbed_simple_presentations = []\n",
    "equivariant_simple_presentation_set = []\n",
    "for presentation in simple_presentations:\n",
    "    if len(presentation) == 2*desired_length:\n",
    "        new_pres = presentation\n",
    "    elif len(presentation) > 2*desired_length:\n",
    "        new_pres = np.zeros(2 * desired_length)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:desired_length:] = presentation[:desired_length:]\n",
    "        new_pres[desired_length::] = presentation[len_rels:len_rels + desired_length:]\n",
    "    elif len(presentation) < 2*desired_length:\n",
    "        new_pres = np.zeros(2 * desired_length)\n",
    "        len_rels = len(presentation) // 2\n",
    "        new_pres[:len_rels:] = presentation[:len_rels:]\n",
    "        new_pres[desired_length:desired_length + len_rels:] = presentation[len_rels::]\n",
    "    scrubbed_simple_presentations += [new_pres]\n",
    "    equivariant_simple_presentation_set += group_equivalency_class(new_pres, 20)\n",
    "\n",
    "print(len(scrubbed_simple_presentations))\n",
    "print(len(equivariant_simple_presentation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/560 [00:29<1:07:22,  7.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m presentation \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(equivariant_simple_presentation_set):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (j, net) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nets):\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     24\u001b[0m             accs[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m top_acc_args \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(accs, \u001b[38;5;241m-\u001b[39mnum_best)\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(presentation, net, temperature, out_len, max_nodes_to_explore)\u001b[0m\n\u001b[0;32m     25\u001b[0m new_state, new_word_lengths, state_updated \u001b[38;5;241m=\u001b[39m ACMove(\n\u001b[0;32m     26\u001b[0m     action,\n\u001b[0;32m     27\u001b[0m     current_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     cyclical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_updated:\n\u001b[1;32m---> 33\u001b[0m     new_state_score \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(new_state, new_state_score)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_state_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m min_score:\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(net, presentation, pres_len, out_len, temperature)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(net, presentation, pres_len, out_len, temperature):\n\u001b[0;32m      2\u001b[0m     one_hot_pres \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(to_one_hot(presentation, out_len))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_pres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m+\u001b[39m pres_len \u001b[38;5;241m*\u001b[39m temperature\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhid1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhid2(z))\n\u001b[0;32m     26\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhid3(z))\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1 - 533: All cases solved by Greedy Search\n",
    "# 1 - 170: all the n = 1 cases. 2720 = 170 * 16\n",
    "# 171 - 308: all the n = 2 cases.\n",
    "# 309 - 406: all the n = 3 cases.\n",
    "# 407 - 458: all the n = 4 cases.\n",
    "# 459 - 493: all the n = 5 cases.\n",
    "# 494 - 517: all the n = 6 cases.\n",
    "# 518 - 533: all the n = 7 cases.\n",
    "\n",
    "# 534 - 565: The n = 2 cases not solved by greedy search \n",
    "num_mutations = 10\n",
    "num_best = 10\n",
    "num_nets = num_best * num_mutations\n",
    "num_evolutions = 30\n",
    "temp_scaling = 5\n",
    "nets = [Net() for _ in range(num_nets)]\n",
    "for i in range(num_evolutions):\n",
    "    temp = 1 / (1 + (i // temp_scaling))\n",
    "    # temp_score = (60 - i)/60\n",
    "    accs = np.array([0 for _ in range(num_nets)])\n",
    "    for presentation in tqdm.tqdm(equivariant_simple_presentation_set):\n",
    "        for (j, net) in enumerate(nets):\n",
    "            if search(presentation, net, 0, 20):\n",
    "                accs[j] += 1\n",
    "\n",
    "    top_acc_args = np.argpartition(accs, -num_best)\n",
    "    best_nets = [nets[k] for k in top_acc_args[-num_best:]]\n",
    "    print(i, \":\", [accs[k] for k in top_acc_args[-num_best:]])\n",
    "    mutated_nets = [net.mutate(num_mutations, temp) for net in best_nets]\n",
    "    nets = [net \n",
    "            for mutated_net in mutated_nets\n",
    "            for net in mutated_net \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2719/2719 [06:48<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 479/2719 [01:39<07:43,  4.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m presentation \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(equivariant_miller_presentation_set[:\u001b[38;5;241m2719\u001b[39m]):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (j, net) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nets):\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     24\u001b[0m             accs[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m top_acc_args \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margpartition(accs, \u001b[38;5;241m-\u001b[39mnum_best)\n",
      "Cell \u001b[1;32mIn[29], line 33\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(presentation, net, temperature, out_len, max_nodes_to_explore)\u001b[0m\n\u001b[0;32m     25\u001b[0m new_state, new_word_lengths, state_updated \u001b[38;5;241m=\u001b[39m ACMove(\n\u001b[0;32m     26\u001b[0m     action,\n\u001b[0;32m     27\u001b[0m     current_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     cyclical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_updated:\n\u001b[1;32m---> 33\u001b[0m     new_state_score \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(new_state, new_state_score)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_state_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m min_score:\n",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(net, presentation, pres_len, out_len, temperature)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(net, presentation, pres_len, out_len, temperature):\n\u001b[0;32m      2\u001b[0m     one_hot_pres \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(to_one_hot(presentation, out_len))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_pres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m+\u001b[39m pres_len \u001b[38;5;241m*\u001b[39m temperature\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhid1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhid2(z))\n\u001b[0;32m     26\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhid3(z))\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\AngusGruen\\Documents\\GitHub\\AC-Solver\\env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1 - 533: All cases solved by Greedy Search\n",
    "# 1 - 170: all the n = 1 cases. 2720 = 170 * 16\n",
    "# 171 - 308: all the n = 2 cases.\n",
    "# 309 - 406: all the n = 3 cases.\n",
    "# 407 - 458: all the n = 4 cases.\n",
    "# 459 - 493: all the n = 5 cases.\n",
    "# 494 - 517: all the n = 6 cases.\n",
    "# 518 - 533: all the n = 7 cases.\n",
    "\n",
    "# 534 - 565: The n = 2 cases not solved by greedy search \n",
    "num_mutations = 10\n",
    "num_best = 5\n",
    "num_nets = num_best * num_mutations\n",
    "num_evolutions = 20\n",
    "temp_scaling = 3\n",
    "# nets = [Net() for _ in range(num_nets)]\n",
    "for i in range(num_evolutions):\n",
    "    temp = 1 / (1 + (i // 2))\n",
    "    # temp_score = (60 - i)/60\n",
    "    accs = np.array([0 for _ in range(num_nets)])\n",
    "    for presentation in tqdm.tqdm(equivariant_miller_presentation_set[:2719]):\n",
    "        for (j, net) in enumerate(nets):\n",
    "            if search(presentation, net, 0, 20):\n",
    "                accs[j] += 1\n",
    "\n",
    "    top_acc_args = np.argpartition(accs, -num_best)\n",
    "    best_nets = [nets[k] for k in top_acc_args[-num_best:]]\n",
    "    print(i, \":\", [accs[k] for k in top_acc_args[-num_best:]])\n",
    "    mutated_nets = [net.mutate(num_mutations, temp) for net in best_nets]\n",
    "    nets = [net \n",
    "            for mutated_net in mutated_nets\n",
    "            for net in mutated_net \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [00:02<00:00, 494.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "max_len = 0\n",
    "for presentation in tqdm.tqdm(scrubbed_miller_presentations):\n",
    "    i = search(presentation, nets[10], 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "        \n",
    "print(acc, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19040/19040 [01:13<00:00, 257.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "max_len = 0\n",
    "for presentation in tqdm.tqdm(equivariant_presentation_set):\n",
    "    i = search(presentation, nets[20], 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "        \n",
    "print(acc, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2719/2719 [00:10<00:00, 255.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "max_len = 0\n",
    "for presentation in tqdm.tqdm(equivariant_presentation_set[:2719]):\n",
    "    i = search(presentation, nets[0], 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "        \n",
    "print(acc, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560/560 [00:05<00:00, 98.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def zero_net(pres):\n",
    "    return torch.zeros(1)\n",
    "\n",
    "acc = 0\n",
    "max_len = 0\n",
    "for presentation in tqdm.tqdm(equivariant_simple_presentation_set):\n",
    "    i = search(presentation, zero_net, 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "print(acc, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2943/19040 [01:22<07:32, 35.55it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m presentation \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(equivariant_miller_presentation_set):\n\u001b[1;32m----> 7\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i:\n\u001b[0;32m      9\u001b[0m         max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(max_len, i)\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(presentation, net, temperature, out_len, max_nodes_to_explore)\u001b[0m\n\u001b[0;32m     25\u001b[0m new_state, new_word_lengths, state_updated \u001b[38;5;241m=\u001b[39m ACMove(\n\u001b[0;32m     26\u001b[0m     action,\n\u001b[0;32m     27\u001b[0m     current_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     cyclical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_updated:\n\u001b[1;32m---> 33\u001b[0m     new_state_score \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_word_lengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(new_state, new_state_score)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_state_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m min_score:\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(net, presentation, pres_len, out_len, temperature)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(net, presentation, pres_len, out_len, temperature):\n\u001b[0;32m      2\u001b[0m     one_hot_pres \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(to_one_hot(presentation, out_len))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_pres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m+\u001b[39m pres_len \u001b[38;5;241m*\u001b[39m temperature\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36mzero_net\u001b[1;34m(pres)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzero_net\u001b[39m(pres):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def zero_net(pres):\n",
    "    return torch.zeros(1)\n",
    "\n",
    "acc = 0\n",
    "max_len = 0\n",
    "for presentation in tqdm.tqdm(equivariant_miller_presentation_set):\n",
    "    i = search(presentation, zero_net, 1, 20)\n",
    "    if i:\n",
    "        max_len = max(max_len, i)\n",
    "        acc += 1\n",
    "print(acc, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  2.,  1., -2., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  2.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrubbed_presentations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrubbed_presentations[0][0::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
